---
title: "Configuration des Providers : Strat√©gie Multi-Mod√®les IA | oh-my-opencode"
sidebarTitle: "Connecter plusieurs services IA"
subtitle: "Configuration des Providers : Strat√©gie Multi-Mod√®les IA"
description: "Apprenez √† configurer les diff√©rents Providers IA de oh-my-opencode, notamment Anthropic, OpenAI, Google et GitHub Copilot, ainsi que le fonctionnement du m√©canisme de repli automatique multi-mod√®les."
tags:
  - "configuration"
  - "providers"
  - "models"
prerequisite:
  - "start-installation"
order: 40
---

# Configuration des Providers : Claude, OpenAI, Gemini et Strat√©gie Multi-Mod√®les

## Ce que vous saurez faire

- Configurer plusieurs Providers IA : Anthropic Claude, OpenAI, Google Gemini, GitHub Copilot, etc.
- Comprendre le m√©canisme de repli par priorit√© multi-mod√®les pour que le syst√®me choisisse automatiquement le meilleur mod√®le disponible
- Attribuer le mod√®le le plus adapt√© √† chaque agent IA et type de t√¢che
- Configurer des services tiers comme Z.ai Coding Plan et OpenCode Zen
- Utiliser la commande doctor pour diagnostiquer la configuration de r√©solution des mod√®les

## Votre situation actuelle

Vous avez install√© oh-my-opencode, mais vous ne savez pas vraiment :
- Comment ajouter plusieurs Providers IA (Claude, OpenAI, Gemini, etc.)
- Pourquoi parfois l'agent n'utilise pas le mod√®le attendu
- Comment configurer diff√©rents mod√®les pour diff√©rentes t√¢ches (par exemple, un mod√®le √©conomique pour la recherche, un mod√®le puissant pour la programmation)
- Comment le syst√®me bascule automatiquement vers un mod√®le de secours quand un Provider est indisponible
- Comment les configurations de mod√®les fonctionnent ensemble dans `opencode.json` et `oh-my-opencode.json`

## Quand utiliser cette technique

- **Configuration initiale** : Vous venez d'installer oh-my-opencode et devez ajouter ou ajuster les Providers IA
- **Nouvel abonnement** : Vous avez souscrit √† un nouveau service IA (comme Gemini Pro) et souhaitez l'int√©grer
- **Optimisation des co√ªts** : Vous voulez que certains agents utilisent des mod√®les moins chers ou plus rapides
- **D√©pannage** : Un agent n'utilise pas le mod√®le pr√©vu et vous devez diagnostiquer le probl√®me
- **Orchestration multi-mod√®les** : Vous souhaitez exploiter les avantages de diff√©rents mod√®les pour construire un workflow de d√©veloppement intelligent

## üéí Avant de commencer

::: warning Pr√©requis
Ce tutoriel suppose que vous avez :
- ‚úÖ Termin√© l'[installation et la configuration initiale](../installation/)
- ‚úÖ Install√© OpenCode (version >= 1.0.150)
- ‚úÖ Une connaissance de base du format de fichier de configuration JSON/JSONC
:::

## Concept cl√©

oh-my-opencode utilise un **syst√®me d'orchestration multi-mod√®les** qui s√©lectionne le mod√®le le plus appropri√© pour chaque agent IA et type de t√¢che en fonction de vos abonnements et de votre configuration.

**Pourquoi le multi-mod√®les ?**

Diff√©rents mod√®les ont diff√©rents points forts :
- **Claude Opus 4.5** : Excellent pour le raisonnement complexe et la conception d'architecture (co√ªteux mais de haute qualit√©)
- **GPT-5.2** : Excellent pour le d√©bogage de code et le conseil strat√©gique
- **Gemini 3 Pro** : Excellent pour les t√¢ches frontend et UI/UX (fortes capacit√©s visuelles)
- **GPT-5 Nano** : Rapide et gratuit, id√©al pour la recherche de code et l'exploration simple
- **GLM-4.7** : Excellent rapport qualit√©-prix, adapt√© √† la recherche et √† la consultation de documentation

L'intelligence de oh-my-opencode r√©side dans : **utiliser le mod√®le le plus adapt√© pour chaque t√¢che, plut√¥t que le m√™me mod√®le pour toutes les t√¢ches**.

## Emplacement des fichiers de configuration

oh-my-opencode prend en charge deux niveaux de configuration :

| Emplacement | Chemin | Priorit√© | Cas d'utilisation |
| --- | --- | --- | --- |
| **Configuration projet** | `.opencode/oh-my-opencode.json` | Basse | Configuration sp√©cifique au projet (versionn√©e avec le code) |
| **Configuration utilisateur** | `~/.config/opencode/oh-my-opencode.json` | Haute | Configuration globale (partag√©e entre tous les projets) |

**R√®gle de fusion** : La configuration utilisateur √©crase la configuration projet.

**Structure de fichier de configuration recommand√©e** :

```jsonc
{
  "$schema": "https://raw.githubusercontent.com/code-yeongyu/oh-my-opencode/master/assets/oh-my-opencode.schema.json",
  // Active l'autocompl√©tion JSON Schema

  "agents": {
    // Surcharges de mod√®les pour les agents
  },
  "categories": {
    // Surcharges de mod√®les pour les cat√©gories
  }
}
```

::: tip Autocompl√©tion Schema
Dans les √©diteurs comme VS Code, apr√®s avoir ajout√© le champ `$schema`, vous obtiendrez une autocompl√©tion compl√®te et une v√©rification de type lors de la saisie de la configuration.
:::

## M√©thodes de configuration des Providers

oh-my-opencode prend en charge 6 Providers principaux. La m√©thode de configuration varie selon le Provider.

### Anthropic Claude (Recommand√©)

**Cas d'utilisation** : Orchestrateur principal Sisyphus et la plupart des agents centraux

**√âtapes de configuration** :

1. **Ex√©cuter l'authentification OpenCode** :
   ```bash
   opencode auth login
   ```

2. **S√©lectionner le Provider** :
   - `Provider` : S√©lectionnez `Anthropic`
   - `Login method` : S√©lectionnez `Claude Pro/Max`

3. **Compl√©ter le flux OAuth** :
   - Le syst√®me ouvrira automatiquement le navigateur
   - Connectez-vous √† votre compte Claude
   - Attendez la fin de l'authentification

4. **V√©rifier le succ√®s** :
   ```bash
   opencode models | grep anthropic
   ```

   Vous devriez voir :
   - `anthropic/claude-opus-4-5`
   - `anthropic/claude-sonnet-4-5`
   - `anthropic/claude-haiku-4-5`

**Mapping des mod√®les** (Configuration par d√©faut de Sisyphus) :

| Agent | Mod√®le par d√©faut | Utilisation |
| --- | --- | --- |
| Sisyphus | `anthropic/claude-opus-4-5` | Orchestrateur principal, raisonnement complexe |
| Prometheus | `anthropic/claude-opus-4-5` | Planification de projet |
| Metis | `anthropic/claude-sonnet-4-5` | Analyse pr√©-planification |
| Momus | `anthropic/claude-opus-4-5` | Revue de plan |

### OpenAI (ChatGPT Plus)

**Cas d'utilisation** : Agent Oracle (revue d'architecture, d√©bogage)

**√âtapes de configuration** :

1. **Ex√©cuter l'authentification OpenCode** :
   ```bash
   opencode auth login
   ```

2. **S√©lectionner le Provider** :
   - `Provider` : S√©lectionnez `OpenAI`
   - `Login method` : S√©lectionnez OAuth ou API Key

3. **Compl√©ter le flux d'authentification** (selon la m√©thode choisie)

4. **V√©rifier le succ√®s** :
   ```bash
   opencode models | grep openai
   ```

**Mapping des mod√®les** (Configuration par d√©faut d'Oracle) :

| Agent | Mod√®le par d√©faut | Utilisation |
| --- | --- | --- |
| Oracle | `openai/gpt-5.2` | Revue d'architecture, d√©bogage |

**Exemple de surcharge manuelle** :

```jsonc
{
  "agents": {
    "oracle": {
      "model": "openai/gpt-5.2",  // Utiliser GPT pour le raisonnement strat√©gique
      "temperature": 0.1
    }
  }
}
```

### Google Gemini (Recommand√©)

**Cas d'utilisation** : Multimodal Looker (analyse m√©dia), t√¢ches Frontend UI/UX

::: tip Fortement recommand√©
Pour l'authentification Gemini, il est fortement recommand√© d'installer le plugin [`opencode-antigravity-auth`](https://github.com/NoeFabris/opencode-antigravity-auth). Il offre :
- √âquilibrage de charge multi-comptes (jusqu'√† 10 comptes)
- Support du syst√®me de variantes (`low`/`high`)
- Double syst√®me de quota (Antigravity + Gemini CLI)
:::

**√âtapes de configuration** :

1. **Ajouter le plugin d'authentification Antigravity** :
   
   √âditez `~/.config/opencode/opencode.json` :
   ```json
   {
     "plugin": [
       "oh-my-opencode",
       "opencode-antigravity-auth@latest"
     ]
   }
   ```

2. **Configurer les mod√®les Gemini** (Important) :
   
   Le plugin Antigravity utilise des noms de mod√®les diff√©rents. Vous devez copier la configuration compl√®te des mod√®les dans `opencode.json`, en faisant attention √† fusionner sans casser les param√®tres existants.

   Mod√®les disponibles (quota Antigravity) :
   - `google/antigravity-gemini-3-pro` ‚Äî variantes : `low`, `high`
   - `google/antigravity-gemini-3-flash` ‚Äî variantes : `minimal`, `low`, `medium`, `high`
   - `google/antigravity-claude-sonnet-4-5` ‚Äî pas de variantes
   - `google/antigravity-claude-sonnet-4-5-thinking` ‚Äî variantes : `low`, `max`
   - `google/antigravity-claude-opus-4-5-thinking` ‚Äî variantes : `low`, `max`

   Mod√®les disponibles (quota Gemini CLI) :
   - `google/gemini-2.5-flash`, `google/gemini-2.5-pro`, `google/gemini-3-flash-preview`, `google/gemini-3-pro-preview`

3. **Surcharger les mod√®les des agents** (dans `oh-my-opencode.json`) :
   
   ```jsonc
   {
     "agents": {
       "multimodal-looker": {
         "model": "google/antigravity-gemini-3-flash"
       }
     }
   }
   ```

4. **Ex√©cuter l'authentification** :
   ```bash
   opencode auth login
   ```

5. **S√©lectionner le Provider** :
   - `Provider` : S√©lectionnez `Google`
   - `Login method` : S√©lectionnez `OAuth with Google (Antigravity)`

6. **Compl√©ter le flux d'authentification** :
   - Le syst√®me ouvrira automatiquement le navigateur
   - Compl√©tez la connexion Google
   - Optionnel : Ajoutez d'autres comptes Google pour l'√©quilibrage de charge

**Mapping des mod√®les** (Configuration par d√©faut) :

| Agent | Mod√®le par d√©faut | Utilisation |
| --- | --- | --- |
| Multimodal Looker | `google/antigravity-gemini-3-flash` | Analyse PDF, images |

### GitHub Copilot (Provider de secours)

**Cas d'utilisation** : Option de secours quand le Provider natif est indisponible

::: info Provider de secours
GitHub Copilot agit comme un Provider proxy, routant les requ√™tes vers les mod√®les sous-jacents de votre abonnement.
:::

**√âtapes de configuration** :

1. **Ex√©cuter l'authentification OpenCode** :
   ```bash
   opencode auth login
   ```

2. **S√©lectionner le Provider** :
   - `Provider` : S√©lectionnez `GitHub`
   - `Login method` : S√©lectionnez `Authenticate via OAuth`

3. **Compl√©ter le flux OAuth GitHub**

4. **V√©rifier le succ√®s** :
   ```bash
   opencode models | grep github-copilot
   ```

**Mapping des mod√®les** (Quand GitHub Copilot est le meilleur Provider disponible) :

| Agent | Mod√®le | Utilisation |
| --- | --- | --- |
| Sisyphus | `github-copilot/claude-opus-4.5` | Orchestrateur principal |
| Oracle | `github-copilot/gpt-5.2` | Revue d'architecture |
| Explore | `opencode/gpt-5-nano` | Exploration rapide |
| Librarian | `zai-coding-plan/glm-4.7` (si Z.ai disponible) | Recherche de documentation |

### Z.ai Coding Plan (Optionnel)

**Cas d'utilisation** : Agent Librarian (recherche multi-d√©p√¥ts, consultation de documentation)

**Caract√©ristiques** :
- Fournit le mod√®le GLM-4.7
- Excellent rapport qualit√©-prix
- Quand activ√©, **l'agent Librarian utilise toujours** `zai-coding-plan/glm-4.7`, ind√©pendamment des autres Providers disponibles

**√âtapes de configuration** :

Utilisez l'installateur interactif :

```bash
bunx oh-my-opencode install
# Quand demand√© : "Do you have a Z.ai Coding Plan subscription?" ‚Üí S√©lectionnez "Yes"
```

**Mapping des mod√®les** (Quand Z.ai est le seul Provider disponible) :

| Agent | Mod√®le | Utilisation |
| --- | --- | --- |
| Sisyphus | `zai-coding-plan/glm-4.7` | Orchestrateur principal |
| Oracle | `zai-coding-plan/glm-4.7` | Revue d'architecture |
| Explore | `zai-coding-plan/glm-4.7-flash` | Exploration rapide |
| Librarian | `zai-coding-plan/glm-4.7` | Recherche de documentation |

### OpenCode Zen (Optionnel)

**Cas d'utilisation** : Fournit les mod√®les pr√©fix√©s `opencode/` (Claude Opus 4.5, GPT-5.2, GPT-5 Nano, Big Pickle)

**√âtapes de configuration** :

```bash
bunx oh-my-opencode install
# Quand demand√© : "Do you have access to OpenCode Zen (opencode/ models)?" ‚Üí S√©lectionnez "Yes"
```

**Mapping des mod√®les** (Quand OpenCode Zen est le meilleur Provider disponible) :

| Agent | Mod√®le | Utilisation |
| --- | --- | --- |
| Sisyphus | `opencode/claude-opus-4-5` | Orchestrateur principal |
| Oracle | `opencode/gpt-5.2` | Revue d'architecture |
| Explore | `opencode/gpt-5-nano` | Exploration rapide |
| Librarian | `opencode/big-pickle` | Recherche de documentation |

## Syst√®me de r√©solution des mod√®les (Priorit√© en 3 √©tapes)

oh-my-opencode utilise un **m√©canisme de priorit√© en 3 √©tapes** pour d√©terminer le mod√®le utilis√© par chaque agent et cat√©gorie. Ce m√©canisme garantit que le syst√®me trouve toujours un mod√®le disponible.

### √âtape 1 : Surcharge utilisateur

Si l'utilisateur a explicitement sp√©cifi√© un mod√®le dans `oh-my-opencode.json`, ce mod√®le est utilis√©.

**Exemple** :
```jsonc
{
  "agents": {
    "oracle": {
      "model": "openai/gpt-5.2"  // Sp√©cifi√© explicitement par l'utilisateur
    }
  }
}
```

Dans ce cas :
- ‚úÖ Utilise directement `openai/gpt-5.2`
- ‚ùå Ignore l'√©tape de repli Provider

### √âtape 2 : Repli Provider

Si l'utilisateur n'a pas explicitement sp√©cifi√© de mod√®le, le syst√®me essaie chaque Provider dans la cha√Æne de priorit√© d√©finie par l'agent jusqu'√† trouver un mod√®le disponible.

**Cha√Æne de priorit√© Provider de Sisyphus** :

```
anthropic ‚Üí github-copilot ‚Üí opencode ‚Üí antigravity ‚Üí google
```

**Processus de r√©solution** :
1. Essayer `anthropic/claude-opus-4-5`
   - Disponible ? ‚Üí Retourner ce mod√®le
   - Indisponible ? ‚Üí Passer √† l'√©tape suivante
2. Essayer `github-copilot/claude-opus-4-5`
   - Disponible ? ‚Üí Retourner ce mod√®le
   - Indisponible ? ‚Üí Passer √† l'√©tape suivante
3. Essayer `opencode/claude-opus-4-5`
   - ...
4. Essayer `google/antigravity-claude-opus-4-5-thinking` (si configur√©)
   - ...
5. Retourner le mod√®le par d√©faut du syst√®me

**Cha√Ænes de priorit√© Provider pour tous les agents** :

| Agent | Mod√®le (sans pr√©fixe) | Cha√Æne de priorit√© Provider |
| --- | --- | --- |
| **Sisyphus** | `claude-opus-4-5` | anthropic ‚Üí github-copilot ‚Üí opencode ‚Üí antigravity ‚Üí google |
| **Oracle** | `gpt-5.2` | openai ‚Üí anthropic ‚Üí google ‚Üí github-copilot ‚Üí opencode |
| **Librarian** | `big-pickle` | opencode ‚Üí github-copilot ‚Üí anthropic |
| **Explore** | `gpt-5-nano` | anthropic ‚Üí opencode |
| **Multimodal Looker** | `gemini-3-flash` | google ‚Üí openai ‚Üí zai-coding-plan ‚Üí anthropic ‚Üí opencode |
| **Prometheus** | `claude-opus-4-5` | anthropic ‚Üí github-copilot ‚Üí opencode ‚Üí antigravity ‚Üí google |
| **Metis** | `claude-sonnet-4-5` | anthropic ‚Üí github-copilot ‚Üí opencode ‚Üí antigravity ‚Üí google |
| **Momus** | `claude-opus-4-5` | anthropic ‚Üí github-copilot ‚Üí opencode ‚Üí antigravity ‚Üí google |
| **Atlas** | `claude-sonnet-4-5` | anthropic ‚Üí github-copilot ‚Üí opencode ‚Üí antigravity ‚Üí google |

**Cha√Ænes de priorit√© Provider pour les cat√©gories** :

| Cat√©gorie | Mod√®le (sans pr√©fixe) | Cha√Æne de priorit√© Provider |
| --- | --- | --- |
| **ultrabrain** | `gpt-5.2-codex` | openai ‚Üí anthropic ‚Üí google ‚Üí github-copilot ‚Üí opencode |
| **artistry** | `gemini-3-pro` | google ‚Üí openai ‚Üí anthropic ‚Üí github-copilot ‚Üí opencode |
| **quick** | `claude-haiku-4-5` | anthropic ‚Üí github-copilot ‚Üí opencode ‚Üí antigravity ‚Üí google |
| **writing** | `gemini-3-flash` | google ‚Üí openai ‚Üí anthropic ‚Üí github-copilot ‚Üí opencode |

### √âtape 3 : Valeur par d√©faut syst√®me

Si tous les Providers sont indisponibles, le mod√®le par d√©faut d'OpenCode est utilis√© (lu depuis `opencode.json`).

**Ordre de priorit√© global** :

```
Surcharge utilisateur > Repli Provider > Valeur par d√©faut syst√®me
```

## Suivez le guide : Configurer plusieurs Providers

### √âtape 1 : Planifier vos abonnements

Avant de commencer la configuration, faites l'inventaire de vos abonnements :

```markdown
- [ ] Anthropic Claude (Pro/Max)
- [ ] OpenAI ChatGPT Plus
- [ ] Google Gemini
- [ ] GitHub Copilot
- [ ] Z.ai Coding Plan
- [ ] OpenCode Zen
```

### √âtape 2 : Utiliser l'installateur interactif (Recommand√©)

oh-my-opencode fournit un installateur interactif qui g√®re automatiquement la plupart de la configuration :

```bash
bunx oh-my-opencode install
```

L'installateur vous demandera :
1. **Do you have a Claude Pro/Max Subscription?**
   - `yes, max20` ‚Üí `--claude=max20`
   - `yes, regular` ‚Üí `--claude=yes`
   - `no` ‚Üí `--claude=no`

2. **Do you have an OpenAI/ChatGPT Plus Subscription?**
   - `yes` ‚Üí `--openai=yes`
   - `no` ‚Üí `--openai=no`

3. **Will you integrate Gemini models?**
   - `yes` ‚Üí `--gemini=yes`
   - `no` ‚Üí `--gemini=no`

4. **Do you have a GitHub Copilot Subscription?**
   - `yes` ‚Üí `--copilot=yes`
   - `no` ‚Üí `--copilot=no`

5. **Do you have access to OpenCode Zen (opencode/ models)?**
   - `yes` ‚Üí `--opencode-zen=yes`
   - `no` ‚Üí `--opencode-zen=no`

6. **Do you have a Z.ai Coding Plan subscription?**
   - `yes` ‚Üí `--zai-coding-plan=yes`
   - `no` ‚Üí `--zai-coding-plan=no`

**Mode non-interactif** (pour l'installation script√©e) :

```bash
bunx oh-my-opencode install --no-tui \
  --claude=max20 \
  --openai=yes \
  --gemini=yes \
  --copilot=no
```

### √âtape 3 : Authentifier chaque Provider

Une fois l'installateur termin√©, authentifiez chaque Provider :

```bash
# Authentifier Anthropic
opencode auth login
# Provider: Anthropic
# Login method: Claude Pro/Max
# Compl√©ter le flux OAuth

# Authentifier OpenAI
opencode auth login
# Provider: OpenAI
# Compl√©ter le flux OAuth

# Authentifier Google Gemini (n√©cessite d'abord le plugin antigravity)
opencode auth login
# Provider: Google
# Login method: OAuth with Google (Antigravity)
# Compl√©ter le flux OAuth

# Authentifier GitHub Copilot
opencode auth login
# Provider: GitHub
# Login method: Authenticate via OAuth
# Compl√©ter OAuth GitHub
```

### √âtape 4 : V√©rifier la configuration

```bash
# V√©rifier la version d'OpenCode
opencode --version
# Devrait √™tre >= 1.0.150

# Voir tous les mod√®les disponibles
opencode models

# Ex√©cuter le diagnostic doctor
bunx oh-my-opencode doctor --verbose
```

**Vous devriez voir** (exemple de sortie doctor) :

```
‚úÖ OpenCode version: 1.0.150
‚úÖ Plugin loaded: oh-my-opencode

üìä Model Resolution:
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ Agent           ‚îÇ Requirement            ‚îÇ Resolved         ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ Sisyphus        ‚îÇ anthropic/claude-opus-4-5  ‚îÇ anthropic/claude-opus-4-5 ‚îÇ
‚îÇ Oracle           ‚îÇ openai/gpt-5.2              ‚îÇ openai/gpt-5.2              ‚îÇ
‚îÇ Librarian        ‚îÇ opencode/big-pickle           ‚îÇ opencode/big-pickle           ‚îÇ
‚îÇ Explore          ‚îÇ anthropic/gpt-5-nano          ‚îÇ anthropic/gpt-5-nano          ‚îÇ
‚îÇ Multimodal Looker‚îÇ google/gemini-3-flash          ‚îÇ google/gemini-3-flash          ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò

‚úÖ All models resolved successfully
```

### √âtape 5 : Personnaliser les mod√®les des agents (Optionnel)

Si vous souhaitez sp√©cifier un mod√®le diff√©rent pour un agent particulier :

```jsonc
{
  "$schema": "https://raw.githubusercontent.com/code-yeongyu/oh-my-opencode/master/assets/oh-my-opencode.schema.json",

  "agents": {
    // Oracle utilise GPT pour la revue d'architecture
    "oracle": {
      "model": "openai/gpt-5.2",
      "temperature": 0.1
    },

    // Librarian utilise un mod√®le moins cher pour la recherche
    "librarian": {
      "model": "opencode/gpt-5-nano",
      "temperature": 0.1
    },

    // Multimodal Looker utilise Antigravity Gemini
    "multimodal-looker": {
      "model": "google/antigravity-gemini-3-flash",
      "variant": "high"
    }
  }
}
```

### √âtape 6 : Personnaliser les mod√®les de cat√©gorie (Optionnel)

Sp√©cifier des mod√®les pour diff√©rents types de t√¢ches :

```jsonc
{
  "$schema": "https://raw.githubusercontent.com/code-yeongyu/oh-my-opencode/master/assets/oh-my-opencode.schema.json",

  "categories": {
    // T√¢ches rapides utilisent un mod√®le √©conomique
    "quick": {
      "model": "opencode/gpt-5-nano",
      "temperature": 0.1
    },

    // T√¢ches frontend utilisent Gemini
    "visual-engineering": {
      "model": "google/gemini-3-pro",
      "temperature": 0.7,
      "prompt_append": "Use shadcn/ui components and Tailwind CSS."
    },

    // T√¢ches de raisonnement avanc√© utilisent GPT Codex
    "ultrabrain": {
      "model": "openai/gpt-5.2-codex",
      "temperature": 0.1
    }
  }
}
```

**Utilisation des cat√©gories** :

```markdown
// Utiliser delegate_task dans la conversation
delegate_task(category="visual", prompt="Create a responsive dashboard component")
delegate_task(category="quick", skills=["git-master"], prompt="Commit these changes")
```

## Points de contr√¥le ‚úÖ

- [ ] `opencode --version` affiche une version >= 1.0.150
- [ ] `opencode models` liste les mod√®les de tous vos Providers configur√©s
- [ ] `bunx oh-my-opencode doctor --verbose` montre que tous les mod√®les des agents sont correctement r√©solus
- [ ] Vous pouvez voir `"oh-my-opencode"` dans le tableau `plugin` de `opencode.json`
- [ ] Essayez d'utiliser un agent (comme Sisyphus) pour confirmer que le mod√®le fonctionne correctement

## Pi√®ges √† √©viter

### ‚ùå Pi√®ge 1 : Oublier d'authentifier le Provider

**Sympt√¥me** : Provider configur√©, mais la r√©solution du mod√®le √©choue.

**Cause** : L'installateur a configur√© le mod√®le, mais l'authentification n'a pas √©t√© compl√©t√©e.

**Solution** :
```bash
opencode auth login
# S√©lectionner le Provider correspondant et compl√©ter l'authentification
```

### ‚ùå Pi√®ge 2 : Nom de mod√®le Antigravity incorrect

**Sympt√¥me** : Gemini configur√©, mais l'agent ne l'utilise pas.

**Cause** : Le plugin Antigravity utilise des noms de mod√®les diff√©rents (`google/antigravity-gemini-3-pro` au lieu de `google/gemini-3-pro`).

**Solution** :
```jsonc
{
  "agents": {
    "multimodal-looker": {
      "model": "google/antigravity-gemini-3-flash"  // Correct
      // model: "google/gemini-3-flash"  // ‚ùå Incorrect
    }
  }
}
```

### ‚ùå Pi√®ge 3 : Mauvais emplacement du fichier de configuration

**Sympt√¥me** : Configuration modifi√©e, mais le syst√®me ne prend pas en compte les changements.

**Cause** : Mauvais fichier de configuration modifi√© (configuration utilisateur vs configuration projet).

**Solution** :
```bash
# Configuration utilisateur (globale, priorit√© haute)
~/.config/opencode/oh-my-opencode.json

# Configuration projet (locale, priorit√© basse)
.opencode/oh-my-opencode.json

# V√©rifier quel fichier est utilis√©
bunx oh-my-opencode doctor --verbose
```

### ‚ùå Pi√®ge 4 : Cha√Æne de priorit√© Provider interrompue

**Sympt√¥me** : Un agent utilise toujours le mauvais mod√®le.

**Cause** : La surcharge utilisateur (√âtape 1) ignore compl√®tement le repli Provider (√âtape 2).

**Solution** : Si vous voulez utiliser le repli automatique, ne codez pas en dur le mod√®le dans `oh-my-opencode.json`, laissez le syst√®me choisir automatiquement selon la cha√Æne de priorit√©.

**Exemple** :
```jsonc
{
  "agents": {
    "oracle": {
      // ‚ùå Cod√© en dur : utilise toujours GPT, m√™me si Anthropic est disponible
      "model": "openai/gpt-5.2"
    }
  }
}
```

Pour utiliser le repli, supprimez le champ `model` et laissez le syst√®me choisir automatiquement :
```jsonc
{
  "agents": {
    "oracle": {
      // ‚úÖ Automatique : anthropic ‚Üí google ‚Üí github-copilot ‚Üí opencode
      "temperature": 0.1
    }
  }
}
```

### ‚ùå Pi√®ge 5 : Z.ai monopolise toujours Librarian

**Sympt√¥me** : M√™me avec d'autres Providers configur√©s, Librarian utilise toujours GLM-4.7.

**Cause** : Quand Z.ai est activ√©, Librarian est cod√© en dur pour utiliser `zai-coding-plan/glm-4.7`.

**Solution** : Si vous ne voulez pas ce comportement, d√©sactivez Z.ai :
```bash
bunx oh-my-opencode install --no-tui --zai-coding-plan=no
```

Ou surchargez manuellement :
```jsonc
{
  "agents": {
    "librarian": {
      "model": "opencode/big-pickle"  // Surcharge le codage en dur de Z.ai
    }
  }
}
```

## R√©sum√© de la le√ßon

- oh-my-opencode prend en charge 6 Providers principaux : Anthropic, OpenAI, Google, GitHub Copilot, Z.ai, OpenCode Zen
- L'installateur interactif `bunx oh-my-opencode install` permet de configurer rapidement plusieurs Providers
- Le syst√®me de r√©solution des mod√®les s√©lectionne dynamiquement les mod√®les via une priorit√© en 3 √©tapes (Surcharge utilisateur ‚Üí Repli Provider ‚Üí Valeur par d√©faut syst√®me)
- Chaque agent et cat√©gorie a sa propre cha√Æne de priorit√© Provider, garantissant qu'un mod√®le disponible est toujours trouv√©
- La commande `doctor --verbose` permet de diagnostiquer la configuration de r√©solution des mod√®les
- Lors de la personnalisation des mod√®les d'agents et de cat√©gories, veillez √† ne pas casser le m√©canisme de repli automatique

## Aper√ßu de la prochaine le√ßon

> Dans la prochaine le√ßon, nous apprendrons **[Strat√©gie multi-mod√®les : Repli automatique et priorit√©s](../model-resolution/)**.
>
> Vous apprendrez :
> - Le workflow complet du syst√®me de r√©solution des mod√®les
> - Comment concevoir la combinaison optimale de mod√®les pour diff√©rentes t√¢ches
> - Les strat√©gies de contr√¥le de concurrence pour les t√¢ches en arri√®re-plan
> - Comment diagnostiquer les probl√®mes de r√©solution des mod√®les

---

## Annexe : R√©f√©rences du code source

<details>
<summary><strong>Cliquez pour voir les emplacements du code source</strong></summary>

> Derni√®re mise √† jour : 2026-01-26

| Fonctionnalit√© | Chemin du fichier | Lignes |
| --- | --- | --- |
| D√©finition du Schema de configuration | [`src/config/schema.ts`](https://github.com/code-yeongyu/oh-my-opencode/blob/main/src/config/schema.ts) | 1-378 |
| Guide d'installation (Configuration Provider) | [`docs/guide/installation.md`](https://github.com/code-yeongyu/oh-my-opencode/blob/main/docs/guide/installation.md) | 1-299 |
| R√©f√©rence de configuration (R√©solution des mod√®les) | [`docs/configurations.md`](https://github.com/code-yeongyu/oh-my-opencode/blob/main/docs/configurations.md) | 391-512 |
| Schema de surcharge des agents | [`src/config/schema.ts:AgentOverrideConfigSchema`](https://github.com/code-yeongyu/oh-my-opencode/blob/main/src/config/schema.ts#L98-L119) | 98-119 |
| Schema de configuration des cat√©gories | [`src/config/schema.ts:CategoryConfigSchema`](https://github.com/code-yeongyu/oh-my-opencode/blob/main/src/config/schema.ts#L154-L172) | 154-172 |
| Documentation des cha√Ænes de priorit√© Provider | [`docs/configurations.md`](https://github.com/code-yeongyu/oh-my-opencode/blob/main/docs/configurations.md#L445-L473) | 445-473 |

**Constantes cl√©s** :
- Aucune : Les cha√Ænes de priorit√© Provider sont cod√©es en dur dans la documentation de configuration, pas comme constantes de code

**Fonctions cl√©s** :
- Aucune : La logique de r√©solution des mod√®les est g√©r√©e par le c≈ìur d'OpenCode, oh-my-opencode fournit la configuration et les d√©finitions de priorit√©

</details>
