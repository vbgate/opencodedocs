---
title: "Configuraci√≥n de Provider: Estrategia Multi-Modelo de IA | oh-my-opencode"
sidebarTitle: "Conectar M√∫ltiples Servicios de IA"
subtitle: "Configuraci√≥n de Provider: Estrategia Multi-Modelo de IA"
description: "Aprende a configurar varios Providers de IA para oh-my-opencode, incluyendo Anthropic, OpenAI, Google y GitHub Copilot, y c√≥mo funciona el mecanismo de degradaci√≥n autom√°tica entre modelos."
tags:
  - "configuration"
  - "providers"
  - "models"
prerequisite:
  - "start-installation"
order: 40
---

# Configuraci√≥n de Provider: Claude, OpenAI, Gemini y Estrategia Multi-Modelo

## Qu√© Aprender√°s

- Configurar m√∫ltiples Providers de IA como Anthropic Claude, OpenAI, Google Gemini y GitHub Copilot
- Comprender el mecanismo de prioridad y degradaci√≥n entre modelos para que el sistema seleccione autom√°ticamente el mejor modelo disponible
- Especificar el modelo m√°s adecuado para diferentes agentes de IA y tipos de tareas
- Configurar servicios de terceros como Z.ai Coding Plan y OpenCode Zen
- Utilizar el comando doctor para diagnosticar la configuraci√≥n de resoluci√≥n de modelos

## Tu Situaci√≥n Actual

Has instalado oh-my-opencode, pero no est√°s muy seguro de:
- C√≥mo agregar m√∫ltiples Providers de IA (Claude, OpenAI, Gemini, etc.)
- Por qu√© a veces los agentes usan modelos diferentes a los esperados
- C√≥mo configurar diferentes modelos para distintas tareas (por ejemplo, tareas de investigaci√≥n con modelos econ√≥micos, tareas de programaci√≥n con modelos potentes)
- C√≥mo el sistema cambia autom√°ticamente a un modelo de respaldo cuando un Provider no est√° disponible
- C√≥mo funcionan juntas las configuraciones de modelos en `opencode.json` y `oh-my-opencode.json`

## Cu√°ndo Usar Esto

- **Configuraci√≥n Inicial**: Acabas de instalar oh-my-opencode y necesitas agregar o ajustar Providers de IA
- **Agregar Nueva Suscripci√≥n**: Has comprado una nueva suscripci√≥n de servicio de IA (como Gemini Pro) y quieres integrarla
- **Optimizar Costos**: Quieres que agentes espec√≠ficos usen modelos m√°s baratos o m√°s r√°pidos
- **Resoluci√≥n de Problemas**: Descubres que un agente no est√° usando el modelo esperado y necesitas diagnosticar el problema
- **Orquestaci√≥n Multi-Modelo**: Deseas aprovechar al m√°ximo las ventajas de diferentes modelos para construir flujos de trabajo de desarrollo inteligentes

## üéí Preparativos Antes de Empezar

::: warning Verificaci√≥n Prerrequisito
Este tutorial asume que ya has:
- ‚úÖ Completado la [Instalaci√≥n y Configuraci√≥n Inicial](../installation/)
- ‚úÖ Instalado OpenCode (versi√≥n >= 1.0.150)
- ‚úÖ Comprendido el formato b√°sico de archivos de configuraci√≥n JSON/JSONC
:::

## Concepto Central

oh-my-opencode utiliza un **sistema de orquestaci√≥n multi-modelo** que selecciona el modelo m√°s adecuado para diferentes agentes de IA y tipos de tareas seg√∫n tus suscripciones y configuraciones.

**¬øPor qu√© necesitamos m√∫ltiples modelos?**

Diferentes modelos tienen diferentes fortalezas:
- **Claude Opus 4.5**: Excelente en razonamiento complejo y dise√±o de arquitectura (costoso, pero alta calidad)
- **GPT-5.2**: Excelente en depuraci√≥n de c√≥digo y consultor√≠a estrat√©gica
- **Gemini 3 Pro**: Excelente en tareas de frontend y UI/UX (fuertes capacidades visuales)
- **GPT-5 Nano**: R√°pido y gratuito, adecuado para b√∫squeda de c√≥digo y exploraci√≥n simple
- **GLM-4.7**: Excelente relaci√≥n calidad-precio, adecuado para investigaci√≥n y b√∫squeda de documentaci√≥n

La inteligencia de oh-my-opencode radica en: **usar el modelo m√°s adecuado para cada tarea, en lugar de usar el mismo modelo para todas las tareas**.

## Ubicaci√≥n de Archivos de Configuraci√≥n

oh-my-opencode admite dos niveles de configuraci√≥n:

| Ubicaci√≥n | Ruta | Prioridad | Escenario de Uso |
|---|---|---|---|
| **Configuraci√≥n de Proyecto** | `.opencode/oh-my-opencode.json` | Baja | Configuraci√≥n espec√≠fica del proyecto (se env√≠a con el repositorio de c√≥digo) |
| **Configuraci√≥n de Usuario** | `~/.config/opencode/oh-my-opencode.json` | Alta | Configuraci√≥n global (compartida entre todos los proyectos) |

**Reglas de Fusi√≥n de Configuraci√≥n**: La configuraci√≥n de usuario anula la configuraci√≥n de proyecto.

**Estructura Recomendada de Archivo de Configuraci√≥n**:

```jsonc
{
  "$schema": "https://raw.githubusercontent.com/code-yeongyu/oh-my-opencode/master/assets/oh-my-opencode.schema.json",
  // Habilitar autocompletado de JSON Schema

  "agents": {
    // Anulaciones de modelos de agentes
  },
  "categories": {
    // Anulaciones de modelos de categor√≠as
  }
}
```

::: tip Autocompletado de Schema
En editores como VS Code, despu√©s de agregar el campo `$schema`, obtendr√°s autocompletado completo y verificaci√≥n de tipos al ingresar la configuraci√≥n.
:::

## M√©todos de Configuraci√≥n de Provider

oh-my-opencode admite 6 Providers principales. Los m√©todos de configuraci√≥n var√≠an seg√∫n el Provider.

### Anthropic Claude (Recomendado)

**Escenarios de Uso**: Orquestador Principal Sisyphus y la mayor√≠a de los agentes principales

**Pasos de Configuraci√≥n**:

1. **Ejecutar Autenticaci√≥n de OpenCode**:
   ```bash
   opencode auth login
   ```

2. **Seleccionar Provider**:
   - `Provider`: Selecciona `Anthropic`
   - `Login method`: Selecciona `Claude Pro/Max`

3. **Completar Flujo OAuth**:
   - El sistema abrir√° autom√°ticamente el navegador
   - Inicia sesi√≥n en tu cuenta de Claude
   - Espera a que se complete la autenticaci√≥n

4. **Verificar √âxito**:
   ```bash
   opencode models | grep anthropic
   ```

   Deber√≠as ver:
   - `anthropic/claude-opus-4-5`
   - `anthropic/claude-sonnet-4-5`
   - `anthropic/claude-haiku-4-5`

**Mapeo de Modelos** (Configuraci√≥n Predeterminada de Sisyphus):

| Agente | Modelo Predeterminado | Uso |
|---|---|---|
| Sisyphus | `anthropic/claude-opus-4-5` | Orquestador Principal, Razonamiento Complejo |
| Prometheus | `anthropic/claude-opus-4-5` | Planificaci√≥n de Proyecto |
| Metis | `anthropic/claude-sonnet-4-5` | An√°lisis Pre-Planificaci√≥n |
| Momus | `anthropic/claude-opus-4-5` | Revisi√≥n de Plan |

### OpenAI (ChatGPT Plus)

**Escenarios de Uso**: Agente Oracle (Revisi√≥n de Arquitectura, Depuraci√≥n)

**Pasos de Configuraci√≥n**:

1. **Ejecutar Autenticaci√≥n de OpenCode**:
   ```bash
   opencode auth login
   ```

2. **Seleccionar Provider**:
   - `Provider`: Selecciona `OpenAI`
   - `Login method`: Selecciona OAuth o API Key

3. **Completar Flujo de Autenticaci√≥n** (seg√∫n el m√©todo seleccionado)

4. **Verificar √âxito**:
   ```bash
   opencode models | grep openai
   ```

**Mapeo de Modelos** (Configuraci√≥n Predeterminada de Oracle):

| Agente | Modelo Predeterminado | Uso |
|---|---|---|
| Oracle | `openai/gpt-5.2` | Revisi√≥n de Arquitectura, Depuraci√≥n |

**Ejemplo de Anulaci√≥n Manual**:

```jsonc
{
  "agents": {
    "oracle": {
      "model": "openai/gpt-5.2",  // Usar GPT para razonamiento estrat√©gico
      "temperature": 0.1
    }
  }
}
```

### Google Gemini (Recomendado)

**Escenarios de Uso**: Multimodal Looker (An√°lisis de Medios), Tareas de Frontend UI/UX

::: tip Altamente Recomendado
Para la autenticaci√≥n de Gemini, se recomienda encarecidamente instalar el plugin [`opencode-antigravity-auth`](https://github.com/NoeFabris/opencode-antigravity-auth). Proporciona:
- Balanceo de carga de m√∫ltiples cuentas (hasta 10 cuentas)
- Soporte para sistema Variant (`low`/`high` variants)
- Sistema dual de cuotas (Antigravity + Gemini CLI)
:::

**Pasos de Configuraci√≥n**:

1. **Agregar Plugin de Autenticaci√≥n Antigravity**:
   
   Edita `~/.config/opencode/opencode.json`:
   ```json
   {
     "plugin": [
       "oh-my-opencode",
       "opencode-antigravity-auth@latest"
     ]
   }
   ```

2. **Configurar Modelos Gemini** (Importante):
   
   El plugin Antigravity usa diferentes nombres de modelos. Necesitas copiar la configuraci√≥n completa del modelo a `opencode.json`, fusionando cuidadosamente para evitar romper la configuraci√≥n existente.

   Modelos disponibles (Cuota Antigravity):
   - `google/antigravity-gemini-3-pro` ‚Äî variants: `low`, `high`
   - `google/antigravity-gemini-3-flash` ‚Äî variants: `minimal`, `low`, `medium`, `high`
   - `google/antigravity-claude-sonnet-4-5` ‚Äî sin variants
   - `google/antigravity-claude-sonnet-4-5-thinking` ‚Äî variants: `low`, `max`
   - `google/antigravity-claude-opus-4-5-thinking` ‚Äî variants: `low`, `max`

   Modelos disponibles (Cuota Gemini CLI):
   - `google/gemini-2.5-flash`, `google/gemini-2.5-pro`, `google/gemini-3-flash-preview`, `google/gemini-3-pro-preview`

3. **Anular Modelo de Agente** (en `oh-my-opencode.json`):
   
   ```jsonc
   {
     "agents": {
       "multimodal-looker": {
         "model": "google/antigravity-gemini-3-flash"
       }
     }
   }
   ```

4. **Ejecutar Autenticaci√≥n**:
   ```bash
   opencode auth login
   ```

5. **Seleccionar Provider**:
   - `Provider`: Selecciona `Google`
   - `Login method`: Selecciona `OAuth with Google (Antigravity)`

6. **Completar Flujo de Autenticaci√≥n**:
   - El sistema abrir√° autom√°ticamente el navegador
   - Completa el inicio de sesi√≥n de Google
   - Opcional: Agrega m√°s cuentas de Google para balanceo de carga

**Mapeo de Modelos** (Configuraci√≥n Predeterminada):

| Agente | Modelo Predeterminado | Uso |
|---|---|---|
| Multimodal Looker | `google/antigravity-gemini-3-flash` | An√°lisis de PDF, Im√°genes |

### GitHub Copilot (Provider de Respaldo)

**Escenarios de Uso**: Opci√≥n de respaldo cuando los Providers nativos no est√°n disponibles

::: info Provider de Respaldo
GitHub Copilot act√∫a como un Provider proxy, enrutando solicitudes al modelo subyacente al que est√°s suscrito.
:::

**Pasos de Configuraci√≥n**:

1. **Ejecutar Autenticaci√≥n de OpenCode**:
   ```bash
   opencode auth login
   ```

2. **Seleccionar Provider**:
   - `Provider`: Selecciona `GitHub`
   - `Login method`: Selecciona `Authenticate via OAuth`

3. **Completar Flujo OAuth de GitHub**

4. **Verificar √âxito**:
   ```bash
   opencode models | grep github-copilot
   ```

**Mapeo de Modelos** (Cuando GitHub Copilot es el mejor Provider disponible):

| Agente | Modelo | Uso |
|---|---|---|
| Sisyphus | `github-copilot/claude-opus-4.5` | Orquestador Principal |
| Oracle | `github-copilot/gpt-5.2` | Revisi√≥n de Arquitectura |
| Explore | `opencode/gpt-5-nano` | Exploraci√≥n R√°pida |
| Librarian | `zai-coding-plan/glm-4.7` (si Z.ai est√° disponible) | B√∫squeda de Documentaci√≥n |

### Z.ai Coding Plan (Opcional)

**Escenarios de Uso**: Agente Librarian (Investigaci√≥n Multi-Repositorio, B√∫squeda de Documentaci√≥n)

**Caracter√≠sticas**:
- Provee modelos GLM-4.7
- Excelente relaci√≥n calidad-precio
- Cuando est√° habilitado, el **agente Librarian siempre usa** `zai-coding-plan/glm-4.7`, independientemente de otros Providers disponibles

**Pasos de Configuraci√≥n**:

Usar el instalador interactivo:

```bash
bunx oh-my-opencode install
# Cuando se pregunte: "¬øTienes una suscripci√≥n Z.ai Coding Plan?" ‚Üí Selecciona "Yes"
```

**Mapeo de Modelos** (Cuando Z.ai es el √∫nico Provider disponible):

| Agente | Modelo | Uso |
|---|---|---|
| Sisyphus | `zai-coding-plan/glm-4.7` | Orquestador Principal |
| Oracle | `zai-coding-plan/glm-4.7` | Revisi√≥n de Arquitectura |
| Explore | `zai-coding-plan/glm-4.7-flash` | Exploraci√≥n R√°pida |
| Librarian | `zai-coding-plan/glm-4.7` | B√∫squeda de Documentaci√≥n |

### OpenCode Zen (Opcional)

**Escenarios de Uso**: Provee modelos con prefijo `opencode/` (Claude Opus 4.5, GPT-5.2, GPT-5 Nano, Big Pickle)

**Pasos de Configuraci√≥n**:

```bash
bunx oh-my-opencode install
# Cuando se pregunte: "¬øTienes acceso a OpenCode Zen (modelos opencode/)?" ‚Üí Selecciona "Yes"
```

**Mapeo de Modelos** (Cuando OpenCode Zen es el mejor Provider disponible):

| Agente | Modelo | Uso |
|---|---|---|
| Sisyphus | `opencode/claude-opus-4-5` | Orquestador Principal |
| Oracle | `opencode/gpt-5.2` | Revisi√≥n de Arquitectura |
| Explore | `opencode/gpt-5-nano` | Exploraci√≥n R√°pida |
| Librarian | `opencode/big-pickle` | B√∫squeda de Documentaci√≥n |

## Sistema de Resoluci√≥n de Modelos (Prioridad en 3 Pasos)

oh-my-opencode utiliza un **mecanismo de prioridad en 3 pasos** para decidir qu√© modelo usar para cada agente y categor√≠a. Este mecanismo asegura que el sistema siempre pueda encontrar un modelo disponible.

### Paso 1: Anulaci√≥n por Usuario

Si el usuario especifica expl√≠citamente un modelo en `oh-my-opencode.json`, se usa ese modelo.

**Ejemplo**:
```jsonc
{
  "agents": {
    "oracle": {
      "model": "openai/gpt-5.2"  // Especificado expl√≠citamente por el usuario
    }
  }
}
```

En este caso:
- ‚úÖ Usa directamente `openai/gpt-5.2`
- ‚ùå Omite el paso de degradaci√≥n de Provider

### Paso 2: Degradaci√≥n de Provider

Si el usuario no especifica expl√≠citamente un modelo, el sistema intentar√° uno por uno seg√∫n la cadena de prioridad de Provider definida por el agente hasta encontrar un modelo disponible.

**Cadena de Prioridad de Provider para Sisyphus**:

```
anthropic ‚Üí github-copilot ‚Üí opencode ‚Üí antigravity ‚Üí google
```

**Flujo de Resoluci√≥n**:
1. Intenta `anthropic/claude-opus-4-5`
   - ¬øDisponible? ‚Üí Devuelve este modelo
   - ¬øNo disponible? ‚Üí Contin√∫a al siguiente paso
2. Intenta `github-copilot/claude-opus-4-5`
   - ¬øDisponible? ‚Üí Devuelve este modelo
   - ¬øNo disponible? ‚Üí Contin√∫a al siguiente paso
3. Intenta `opencode/claude-opus-4-5`
   - ...
4. Intenta `google/antigravity-claude-opus-4-5-thinking` (si est√° configurado)
   - ...
5. Devuelve el modelo predeterminado del sistema

**Cadenas de Prioridad de Provider para Todos los Agentes**:

| Agente | Modelo (sin prefijo) | Cadena de Prioridad de Provider |
|---|---|---|
| **Sisyphus** | `claude-opus-4-5` | anthropic ‚Üí github-copilot ‚Üí opencode ‚Üí antigravity ‚Üí google |
| **Oracle** | `gpt-5.2` | openai ‚Üí anthropic ‚Üí google ‚Üí github-copilot ‚Üí opencode |
| **Librarian** | `big-pickle` | opencode ‚Üí github-copilot ‚Üí anthropic |
| **Explore** | `gpt-5-nano` | anthropic ‚Üí opencode |
| **Multimodal Looker** | `gemini-3-flash` | google ‚Üí openai ‚Üí zai-coding-plan ‚Üí anthropic ‚Üí opencode |
| **Prometheus** | `claude-opus-4-5` | anthropic ‚Üí github-copilot ‚Üí opencode ‚Üí antigravity ‚Üí google |
| **Metis** | `claude-sonnet-4-5` | anthropic ‚Üí github-copilot ‚Üí opencode ‚Üí antigravity ‚Üí google |
| **Momus** | `claude-opus-4-5` | anthropic ‚Üí github-copilot ‚Üí opencode ‚Üí antigravity ‚Üí google |
| **Atlas** | `claude-sonnet-4-5` | anthropic ‚Üí github-copilot ‚Üí opencode ‚Üí antigravity ‚Üí google |

**Cadenas de Prioridad de Provider para Categor√≠as**:

| Categor√≠a | Modelo (sin prefijo) | Cadena de Prioridad de Provider |
|---|---|---|
| **ultrabrain** | `gpt-5.2-codex` | openai ‚Üí anthropic ‚Üí google ‚Üí github-copilot ‚Üí opencode |
| **artistry** | `gemini-3-pro` | google ‚Üí openai ‚Üí anthropic ‚Üí github-copilot ‚Üí opencode |
| **quick** | `claude-haiku-4-5` | anthropic ‚Üí github-copilot ‚Üí opencode ‚Üí antigravity ‚Üí google |
| **writing** | `gemini-3-flash` | google ‚Üí openai ‚Üí anthropic ‚Üí github-copilot ‚Üí opencode |

### Paso 3: Predeterminado del Sistema

Si todos los Providers no est√°n disponibles, usa el modelo predeterminado de OpenCode (lee de `opencode.json`).

**Orden de Prioridad Global**:

```
Anulaci√≥n por Usuario > Degradaci√≥n de Provider > Predeterminado del Sistema
```

## S√≠gueme: Configurar M√∫ltiples Providers

### Paso 1: Planificar tus Suscripciones

Antes de comenzar la configuraci√≥n, organiza primero el estado de tus suscripciones:

```markdown
- [ ] Anthropic Claude (Pro/Max)
- [ ] OpenAI ChatGPT Plus
- [ ] Google Gemini
- [ ] GitHub Copilot
- [ ] Z.ai Coding Plan
- [ ] OpenCode Zen
```

### Paso 2: Usar el Instalador Interactivo (Recomendado)

oh-my-opencode proporciona un instalador interactivo que maneja autom√°ticamente la mayor parte de la configuraci√≥n:

```bash
bunx oh-my-opencode install
```

El instalador preguntar√°:
1. **Do you have a Claude Pro/Max Subscription?**
   - `yes, max20` ‚Üí `--claude=max20`
   - `yes, regular` ‚Üí `--claude=yes`
   - `no` ‚Üí `--claude=no`

2. **Do you have an OpenAI/ChatGPT Plus Subscription?**
   - `yes` ‚Üí `--openai=yes`
   - `no` ‚Üí `--openai=no`

3. **Will you integrate Gemini models?**
   - `yes` ‚Üí `--gemini=yes`
   - `no` ‚Üí `--gemini=no`

4. **Do you have a GitHub Copilot Subscription?**
   - `yes` ‚Üí `--copilot=yes`
   - `no` ‚Üí `--copilot=no`

5. **Do you have access to OpenCode Zen (opencode/ models)?**
   - `yes` ‚Üí `--opencode-zen=yes`
   - `no` ‚Üí `--opencode-zen=no`

6. **Do you have a Z.ai Coding Plan subscription?**
   - `yes` ‚Üí `--zai-coding-plan=yes`
   - `no` ‚Üí `--zai-coding-plan=no`

**Modo No Interactivo** (adecuado para instalaci√≥n script):

```bash
bunx oh-my-opencode install --no-tui \
  --claude=max20 \
  --openai=yes \
  --gemini=yes \
  --copilot=no
```

### Paso 3: Autenticar Cada Provider

Despu√©s de que el instalador configure, autentica uno por uno:

```bash
# Autenticar Anthropic
opencode auth login
# Provider: Anthropic
# Login method: Claude Pro/Max
# Completar flujo OAuth

# Autenticar OpenAI
opencode auth login
# Provider: OpenAI
# Completar flujo OAuth

# Autenticar Google Gemini (necesita instalar plugin antigravity primero)
opencode auth login
# Provider: Google
# Login method: OAuth with Google (Antigravity)
# Completar flujo OAuth

# Autenticar GitHub Copilot
opencode auth login
# Provider: GitHub
# Login method: Authenticate via OAuth
# Completar GitHub OAuth
```

### Paso 4: Verificar Configuraci√≥n

```bash
# Verificar versi√≥n de OpenCode
opencode --version
# Deber√≠a ser >= 1.0.150

# Ver todos los modelos disponibles
opencode models

# Ejecutar diagn√≥stico doctor
bunx oh-my-opencode doctor --verbose
```

**Deber√≠as ver** (ejemplo de salida doctor):

```
‚úÖ OpenCode version: 1.0.150
‚úÖ Plugin loaded: oh-my-opencode

üìä Model Resolution:
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ Agent           ‚îÇ Requirement            ‚îÇ Resolved         ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ Sisyphus        ‚îÇ anthropic/claude-opus-4-5  ‚îÇ anthropic/claude-opus-4-5 ‚îÇ
‚îÇ Oracle           ‚îÇ openai/gpt-5.2              ‚îÇ openai/gpt-5.2              ‚îÇ
‚îÇ Librarian        ‚îÇ opencode/big-pickle           ‚îÇ opencode/big-pickle           ‚îÇ
‚îÇ Explore          ‚îÇ anthropic/gpt-5-nano          ‚îÇ anthropic/gpt-5-nano          ‚îÇ
‚îÇ Multimodal Looker‚îÇ google/gemini-3-flash          ‚îÇ google/gemini-3-flash          ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò

‚úÖ All models resolved successfully
```

### Paso 5: Personalizar Modelo de Agente (Opcional)

Si deseas especificar un modelo diferente para un agente espec√≠fico:

```jsonc
{
  "$schema": "https://raw.githubusercontent.com/code-yeongyu/oh-my-opencode/master/assets/oh-my-opencode.schema.json",

  "agents": {
    // Oracle usa GPT para revisi√≥n de arquitectura
    "oracle": {
      "model": "openai/gpt-5.2",
      "temperature": 0.1
    },

    // Librarian usa un modelo m√°s barato para investigaci√≥n
    "librarian": {
      "model": "opencode/gpt-5-nano",
      "temperature": 0.1
    },

    // Multimodal Looker usa Antigravity Gemini
    "multimodal-looker": {
      "model": "google/antigravity-gemini-3-flash",
      "variant": "high"
    }
  }
}
```

### Paso 6: Personalizar Modelo de Categor√≠a (Opcional)

Especificar modelos para diferentes tipos de tareas:

```jsonc
{
  "$schema": "https://raw.githubusercontent.com/code-yeongyu/oh-my-opencode/master/assets/oh-my-opencode.schema.json",

  "categories": {
    // Tareas r√°pidas usan modelos baratos
    "quick": {
      "model": "opencode/gpt-5-nano",
      "temperature": 0.1
    },

    // Tareas frontend usan Gemini
    "visual-engineering": {
      "model": "google/gemini-3-pro",
      "temperature": 0.7,
      "prompt_append": "Use shadcn/ui components and Tailwind CSS."
    },

    // Tareas de razonamiento de alta inteligencia usan GPT Codex
    "ultrabrain": {
      "model": "openai/gpt-5.2-codex",
      "temperature": 0.1
    }
  }
}
```

**Usar Categor√≠a**:

```markdown
// Usar delegate_task en conversaci√≥n
delegate_task(category="visual", prompt="Create a responsive dashboard component")
delegate_task(category="quick", skills=["git-master"], prompt="Commit these changes")
```

## Punto de Verificaci√≥n ‚úÖ

- [ ] `opencode --version` muestra versi√≥n >= 1.0.150
- [ ] `opencode models` lista los modelos de todos los Providers que configuraste
- [ ] `bunx oh-my-opencode doctor --verbose` muestra que todos los modelos de agentes se resolvieron correctamente
- [ ] Puedes ver `"oh-my-opencode"` en el array `plugin` en `opencode.json`
- [ ] Intenta usar un agente (como Sisyphus), confirma que el modelo funciona correctamente

## Advertencias de Trampas

### ‚ùå Trampa 1: Olvidar Autenticar Provider

**S√≠ntoma**: Configuraste el Provider, pero la resoluci√≥n del modelo falla.

**Causa**: El instalador configur√≥ el modelo, pero no completaste la autenticaci√≥n.

**Soluci√≥n**:
```bash
opencode auth login
# Selecciona el Provider correspondiente y completa la autenticaci√≥n
```

### ‚ùå Trampa 2: Nombre de Modelo Antigravity Incorrecto

**S√≠ntoma**: Configuraste Gemini, pero el agente no lo usa.

**Causa**: El plugin Antigravity usa diferentes nombres de modelos (`google/antigravity-gemini-3-pro` en lugar de `google/gemini-3-pro`).

**Soluci√≥n**:
```jsonc
{
  "agents": {
    "multimodal-looker": {
      "model": "google/antigravity-gemini-3-flash"  // Correcto
      // model: "google/gemini-3-flash"  // ‚ùå Incorrecto
    }
  }
}
```

### ‚ùå Trampa 3: Ubicaci√≥n de Archivo de Configuraci√≥n Incorrecta

**S√≠ntoma**: Modificaste la configuraci√≥n, pero el sistema no la aplic√≥.

**Causa**: Modificaste el archivo de configuraci√≥n incorrecto (configuraci√≥n de usuario vs configuraci√≥n de proyecto).

**Soluci√≥n**:
```bash
# Configuraci√≥n de Usuario (global, prioridad alta)
~/.config/opencode/oh-my-opencode.json

# Configuraci√≥n de Proyecto (local, prioridad baja)
.opencode/oh-my-opencode.json

# Verificar qu√© archivo se est√° usando
bunx oh-my-opencode doctor --verbose
```

### ‚ùå Trampa 4: Cadena de Prioridad de Provider Interrumpida

**S√≠ntoma**: Un agente siempre usa el modelo incorrecto.

**Causa**: La anulaci√≥n por usuario (Paso 1) omite completamente la degradaci√≥n de Provider (Paso 2).

**Soluci√≥n**: Si deseas aprovechar la degradaci√≥n autom√°tica, no codifiques el modelo en `oh-my-opencode.json`, sino deja que el sistema seleccione autom√°ticamente seg√∫n la cadena de prioridad.

**Ejemplo**:
```jsonc
{
  "agents": {
    "oracle": {
      // ‚ùå Codificado: siempre usa GPT, incluso si Anthropic est√° disponible
      "model": "openai/gpt-5.2"
    }
  }
}
```

Si deseas aprovechar la degradaci√≥n, elimina el campo `model` y deja que el sistema seleccione autom√°ticamente:
```jsonc
{
  "agents": {
    "oracle": {
      // ‚úÖ Autom√°tico: anthropic ‚Üí google ‚Üí github-copilot ‚Üí opencode
      "temperature": 0.1
    }
  }
}
```

### ‚ùå Trampa 5: Z.ai Siempre Ocupa Librarian

**S√≠ntoma**: Incluso cuando configuras otros Providers, Librarian sigue usando GLM-4.7.

**Causa**: Cuando Z.ai est√° habilitado, Librarian est√° codificado para usar `zai-coding-plan/glm-4.7`.

**Soluci√≥n**: Si no necesitas este comportamiento, deshabilita Z.ai:
```bash
bunx oh-my-opencode install --no-tui --zai-coding-plan=no
```

O anula manualmente:
```jsonc
{
  "agents": {
    "librarian": {
      "model": "opencode/big-pickle"  // Anular codificaci√≥n de Z.ai
    }
  }
}
```

## Resumen de la Lecci√≥n

- oh-my-opencode admite 6 Providers principales: Anthropic, OpenAI, Google, GitHub Copilot, Z.ai, OpenCode Zen
- Usa el instalador interactivo `bunx oh-my-opencode install` para configurar r√°pidamente m√∫ltiples Providers
- El sistema de resoluci√≥n de modelos selecciona din√°micamente modelos mediante prioridad en 3 pasos (anulaci√≥n por usuario ‚Üí degradaci√≥n de Provider ‚Üí predeterminado del sistema)
- Cada agente y Categor√≠a tiene su propia cadena de prioridad de Provider, asegurando que siempre se pueda encontrar un modelo disponible
- Usa el comando `doctor --verbose` para diagnosticar la configuraci√≥n de resoluci√≥n de modelos
- Al personalizar modelos de agentes y categor√≠as, debes tener cuidado de no romper el mecanismo de degradaci√≥n autom√°tica

## Vista Previa de la Siguiente Lecci√≥n

> En la siguiente lecci√≥n aprenderemos **[Estrategia Multi-Modelo: Degradaci√≥n Autom√°tica y Prioridades](../model-resolution/)**.>
> Aprender√°s:
> - El flujo de trabajo completo del sistema de resoluci√≥n de modelos
> - C√≥mo dise√±ar combinaciones √≥ptimas de modelos para diferentes tareas
> - Estrategias de control de concurrencia en tareas en segundo plano
> - C√≥mo diagnosticar problemas de resoluci√≥n de modelos

---

## Ap√©ndice: Referencia de C√≥digo Fuente

<details>
<summary><strong>Haz clic para expandir y ver la ubicaci√≥n del c√≥digo fuente</strong></summary>

> √öltima actualizaci√≥n: 2026-01-26

| Funci√≥n | Ruta del Archivo | N√∫mero de L√≠nea |
|---|---|---|
| Definici√≥n del Schema de Configuraci√≥n | [`src/config/schema.ts`](https://github.com/code-yeongyu/oh-my-opencode/blob/main/src/config/schema.ts) | 1-378 |
| Gu√≠a de Instalaci√≥n (Configuraci√≥n de Provider) | [`docs/guide/installation.md`](https://github.com/code-yeongyu/oh-my-opencode/blob/main/docs/guide/installation.md) | 1-299 |
| Referencia de Configuraci√≥n (Resoluci√≥n de Modelos) | [`docs/configurations.md`](https://github.com/code-yeongyu/oh-my-opencode/blob/main/docs/configurations.md) | 391-512 |
| Schema de Configuraci√≥n de Anulaci√≥n de Agente | [`src/config/schema.ts:AgentOverrideConfigSchema`](https://github.com/code-yeongyu/oh-my-opencode/blob/main/src/config/schema.ts#L98-L119) | 98-119 |
| Schema de Configuraci√≥n de Categor√≠a | [`src/config/schema.ts:CategoryConfigSchema`](https://github.com/code-yeongyu/oh-my-opencode/blob/main/src/config/schema.ts#L154-L172) | 154-172 |
| Documentaci√≥n de Cadena de Prioridad de Provider | [`docs/configurations.md`](https://github.com/code-yeongyu/oh-my-opencode/blob/main/docs/configurations.md#L445-L473) | 445-473 |

**Constantes Clave**:
- Ninguna: La cadena de prioridad de Provider est√° codificada en la documentaci√≥n de configuraci√≥n, no es una constante de c√≥digo

**Funciones Clave**:
- Ninguna: La l√≥gica de resoluci√≥n de modelos es manejada por el n√∫cleo de OpenCode, oh-my-opencode proporciona definiciones de configuraci√≥n y prioridades

</details>
